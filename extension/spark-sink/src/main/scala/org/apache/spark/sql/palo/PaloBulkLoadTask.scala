/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.sql.palo

import java.io.{BufferedInputStream, BufferedOutputStream, BufferedWriter, DataOutputStream, File, FileInputStream, FileOutputStream, InputStream, IOException, OutputStream, OutputStreamWriter}
import java.net.{HttpURLConnection, ProtocolException, SocketTimeoutException, URL}
import java.nio.ByteBuffer

import org.json4s._
import org.json4s.jackson.JsonMethods._

import org.apache.spark.internal.Logging
import org.apache.spark.sql.{AnalysisException, SparkSession}
import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.sql.types.{StringType, StructType}

/**
 * Use `BULK LOAD` to load data to Palo by using http protocol to send data.
 * To use http `PUT` data to palo, we need write intermediate contents to tmp files on
 * local file system and when load finished, delete them
 *
 * Note: the size of tmp file should not exceed 1GB (advise)
 */
private[palo] class PaloBulkLoadTask (
    sparkSession: SparkSession,
    batchId: Long,
    checkpointRoot: String,
    parameters: Map[String, String],
    schema: StructType)
  extends PaloWriteTask(sparkSession, batchId, checkpointRoot, parameters, schema) with Logging {

  // use the "label" as the file name which will send to palo by http protocol
  // the tmp file to store data generated by Dataset
  private[palo] var file = new File(label)
  private[palo] val httpMaxRetries: Int =
      parameters.getOrElse(PaloConfig.HTTP_MAX_RETRIES, "3").toInt
  private[palo] val httpConnectTimeoutMs: Int =
      parameters.getOrElse(PaloConfig.HTTP_CONNECT_TIMEOUT_MS, "60000").toInt
  private[palo] val httpReadTimeoutMs: Int =
      parameters.getOrElse(PaloConfig.HTTP_READ_TIMEOUT_MS, "10000").toInt
  private[palo] val bulkLoadReadBufferSize: Int =
      parameters.getOrElse(PaloConfig.BULK_LOAD_READ_BUFFERSIZE, "1048576").toInt // 1MB
  private[palo] val httpPort: String = parameters.getOrElse(PaloConfig.HTTP_PORT, "8030")
  private[palo] val separator: String =
      parameters.getOrElse(PaloConfig.SEPARATOR, ",") // default ","
  private[palo] val maxFilterRatio =
      parameters.getOrElse(PaloConfig.MAX_FILTER_RATIO, "0").toDouble
  assert(maxFilterRatio >= 0 && maxFilterRatio <= 1, "maxFilterRatio must between [0,1]")

  private[palo] val urlSuffix = s"api/${database}/${table}/_load" +
          s"?label=${label}&${PaloConfig.MAX_FILTER_RATIO}=${maxFilterRatio}" +
          s"&column_separator=${separator}"

  private[palo] var outputStream: FileOutputStream = null
  private[palo] var writer: BufferedWriter = null

  // init outputStream to write tmp file
  init

  private def init() {
    try {
      // dataPath may exists for failover, delete the dataPath and create new one firstly
      if (file.exists) {
        file.delete
        logInfo(s"file:${file.getAbsolutePath} exists, delete it successfully")
      }
      assert(file.createNewFile, "create file failed when init")
      outputStream = new FileOutputStream(file)
      writer = new BufferedWriter(new OutputStreamWriter(outputStream, "UTF-8"))

      logInfo(s"init successfully, create a new file:${file.getAbsolutePath} to store contents")
    } catch {
      case e: IOException =>
        logError(s"PaloBulkLoadTask init failed: ${e.getMessage}")
        try {
          if (outputStream != null) {
            outputStream.close
          }
        } catch {
          case e1: IOException =>
          logError(s"close outputStream error when init failed:${e1.getMessage}")
        }
        try {
          if (writer != null) {
            writer.close
          }
        } catch {
           case e1: IOException =>
           logError(s"close BufferedWriter error when init failed:${e1.getMessage}")
        }
        throw e
    }
  }

  override def writeToFile(content: String): Long = {
    writer.write(content, 0, content.length)
    content.getBytes("UTF-8").length
  }

  override def loadFileToPaloTable() {
    // 1. flush content inf buffer to local disk
    try {
      writer.flush
      outputStream.flush
      outputStream.close
      writer.close
    } catch {
      case e: IOException =>
        logError(s"loadFileToPaloTable fail: ${e.getMessage}")
        throw e
    }

    // 2. send File to Palo by http
    loadByHttp(generateDistUrl)
  }

  override def deleteFile() {
    if (needDelete && file.exists) {
      try {
        if (file.delete) {
          logInfo(s"delete ${file.getAbsolutePath} successfully")
        } else {
          logWarning(s"delete ${file.getAbsolutePath} failed")
        }
      } catch {
        case e: IOException =>
        logError(s"delete file: ${file.getAbsolutePath} failed for: ${e.getMessage}")
        throw e
      }
    }
  }

  /**
   * generate dist url.
   */
  private[palo] def generateDistUrl(): URL = {
    new URL(s"http://${parameters(PaloConfig.COMPUTENODEURL)}/${urlSuffix}")
  }

  private[palo] def loadByHttp(url: URL): Unit = {
    var httpConnection: HttpURLConnection = null
    var output: DataOutputStream = null
    var input: InputStream = null
    var retryTimes = 0
    while(retryTimes <= httpMaxRetries) {
      try {
        val userPassword = s"${username}:${password}"
        val encoding = new String(new sun.misc.BASE64Encoder().encode(userPassword.getBytes()))
        httpConnection = url.openConnection().asInstanceOf[HttpURLConnection]

        val currentConnectionTimeoutMs = httpConnectTimeoutMs * (retryTimes + 1)
        val currentReadTimeoutMs = httpReadTimeoutMs * (retryTimes + 1)
        httpConnection.setConnectTimeout(currentConnectionTimeoutMs) // 60 seconds
        httpConnection.setReadTimeout(currentReadTimeoutMs) // 10 seconds
        httpConnection.setDoInput(true)
        httpConnection.setDoOutput(true)
        httpConnection.setRequestMethod("PUT")
        httpConnection.setRequestProperty("Charset", "UTF-8")
        httpConnection.setRequestProperty("Content-Type", "text/plain")
        httpConnection.setRequestProperty("Content-Length", s"${file.length}")
        httpConnection.setRequestProperty("Expect", "100-continue")
        httpConnection.setRequestProperty("Authorization", "Basic " + encoding)
        httpConnection.setUseCaches(false)
        httpConnection.setInstanceFollowRedirects(true) // must set redirect as true

        // write file's content to outputStream of httpURConnection
        output = new DataOutputStream(new BufferedOutputStream(httpConnection.getOutputStream()))
        val fileInputStream = new BufferedInputStream(new FileInputStream(file))
        val buffer = new Array[Byte](bulkLoadReadBufferSize)
        var length = -1
        while ( {length = fileInputStream.read(buffer); length != -1} ) {
          output.write(buffer, 0, length)
        }
        output.flush()
        fileInputStream.close()
        logDebug(s"request url: ${url}")

        // check responseCode
        val responseCode = httpConnection.getResponseCode
        logDebug(s"responseCode:$responseCode, responseMsg:${httpConnection.getResponseMessage}")
        if (responseCode == HttpURLConnection.HTTP_OK)  {
          input = httpConnection.getInputStream()
          val builder = new StringBuilder()
          val readBuf = new Array[Byte](1024)
          var readNum = input.read(readBuf)
          while (readNum != - 1) {
            builder.append(new String(readBuf, 0, readNum, "UTF-8"))
            readNum = input.read(readBuf)
          }

          // check msg return  by palo
          val responseJson = parse(builder.toString)
          (responseJson \\ "status") match {
            case JString(code) =>
              if (!code.toLowerCase().equals("success")) {
                logWarning(s"code:${code}, msg:${responseJson \\ "msg"}")
              }
            case _ =>
              logWarning("no respsonse status")
          }
          retryTimes = httpMaxRetries + 1
        } else { // http request failed, retry again
          retryTimes += 1
          if (retryTimes == httpMaxRetries + 1) {
            logError(s"after retry ${httpMaxRetries} times, http request failed")
            throw new PaloHttpException(s"after retry ${httpMaxRetries} times, " +
                s"http request failed, return code:${responseCode}")
          } else {
            logWarning(
                s"http request failed, return code: ${responseCode}, retry ${retryTimes} time")
          }
        }
      } catch {
        case e: ProtocolException =>
          logError(s"throw ProtocolException ${e.getMessage()}, failed to load label:${label}")
          // Throw exception directly to avoid unnecessary retry.
          throw e
        case e: IOException =>
          logError(s"throw IOException ${e.getMessage()}, failed to load label:${label}")
          // Throw exception directly to avoid unnecessary retry.
          throw e
        case e: java.net.SocketTimeoutException =>
          // retry
          retryTimes += 1
          if (retryTimes == httpMaxRetries + 1) {
            needDelete = false
            logWarning(s"after retry ${httpMaxRetries}, throw exception " +
                s"${e.getMessage()}, failed to load label: ${label}, " +
                s"retain file for restore, path:${file.getAbsolutePath()}")
            throw e
          } else {
            logWarning(s"throw exception ${e.getMessage()}, retry time: ${retryTimes}")
            doWait()
          }
        case e: Throwable => throw e
      } finally {
        try {
          if (output != null) {
              output.close();
              output = null;
          }
        } catch {
          case e: IOException =>
            logWarning("exception when close: " + e.getMessage);
        } finally {
          try {
            if (input != null) {
                input.close();
                input = null;
            }
          } catch {
            case e: IOException =>
              logWarning("exception when close: " + e.getMessage());
          }
        }
      }
    } // end while (retryTime < httpMaxRetries)
  }
} // end class of PaloBulkLoadTask

class PaloHttpException(msg: String) extends Exception(msg) {}
